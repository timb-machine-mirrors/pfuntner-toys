#! /usr/bin/env python3

import sys
import json
import signal
import logging
import hashlib
import argparse

def md5sum(data):
  hasher = hashlib.md5()
  hasher.update(data.encode())
  return hasher.hexdigest()

import bruno_tools

parser = argparse.ArgumentParser(description='Correlate a combined output file with individual files - good for concurrent Jenkins stages')
parser.add_argument('combined_path', metavar='combined-path', help='Path to combined output file')
parser.add_argument('paths', nargs='+', help='Paths to one or more individual files')
parser.add_argument('-j', '--json', action='store_true', help='Generate JSON output')
parser.add_argument('-v', '--verbose', action='count', help='Enable debugging')
args = parser.parse_args()

logging.basicConfig(format='%(asctime)s %(levelname)s %(pathname)s:%(lineno)d %(msg)s')
log = logging.getLogger(sys.argv[0])
log.setLevel(logging.WARNING - (args.verbose or 0)*10)

signal.signal(signal.SIGPIPE, lambda signum, stack_frame: exit(0))

data = dict()
for path in args.paths:
  with open(path) as stream:
    for line in stream.read().splitlines():
      sum = md5sum(line)
      if not sum in data:
        data[sum] = set()
      data[sum].add(path)

table = bruno_tools.Table('File', 'Line') if not args.json else []

with open(args.combined_path) as stream:
  for line in stream.read().splitlines():
    sum = md5sum(line)
    if args.json:
      table.append({
        'files': sorted(list(data.get(sum, []))),
        'line': line,
      })
    else:
      table.add(','.join(sorted(data[sum])) if sum in data else 'None', line)

if args.json:
  json.dump(table, sys.stdout, indent=2)
  print()
else:
  table.close()
